version: '3.8'
#x-airflow-common:
#  &airflow-common
#  image: bitnami/airflow:latest
#  environment:
#    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@show_time_db:5432/dev_showtime
#    - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
#    - AIRFLOW__CORE__LOAD_EXAMPLES=False
#    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
#  volumes:
#    - ./plugins:/opt/bitnami/airflow/plugins
#    - ./dags:/opt/bitnami/airflow/dags
#    - ./db_backups:/opt/bitnami/airflow/db_backups
#    - /var/run/docker.sock:/var/run/docker.sock
#    - /config_airflow_requirement/requirements.txt:/opt/bitnami/airflow/requirements.txt
#  depends_on:
#    - db
services:
  db:
    container_name: show_time_db
    image: postgres:14.2-alpine
#    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=dev_showtime
    ports:
      - '5432:5432'
    volumes:
      - ./local_pgdata:/var/lib/postgresql/data
  pgadmin:
    build:  ./docker/pgadmin
    privileged: true
    container_name: pgadmin4_container
    #restart: always
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: showtime@dev.com
      PGADMIN_DEFAULT_PASSWORD: admin
    volumes:
      - ./pgadmin-data:/var/lib/pgadmin:rw
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.9.3
    container_name: elasticsearch
    privileged: true
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx2g"
      - ELASTIC_PASSWORD=elastictest2
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - __w/showtime_API/showtime_API/elasticsearch-data:/usr/share/elasticsearch/data:rw
      - __w/showtime_API/showtime_API/elasticsearch-config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - 9200:9200
      - 9300:9300
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2000M
        reservations:
          cpus: '1'
          memory: 512M
  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:7.9.3
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=elastictest2
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 500M
        reservations:
          cpus: '1'
          memory: 500M
  kibana_aws:
    container_name: kibana_aws
    image: docker.elastic.co/kibana/kibana:7.9.3
    environment:
      - ELASTICSEARCH_HOSTS=https://showtime-app.click/elasticsearch
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=a8gtr5ql
    ports:
      - 5602:5601
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 500M
        reservations:
          cpus: '1'
          memory: 500M
#    volumes:
#      - ./kibana-config/kibana.yml:/usr/share/kibana/config/kibana.yml
  logstash:
    image: kevinpsirius/centos_logstash:v1
    container_name: logstash
    privileged: true
    volumes:
      - __w/showtime_API/showtime_API/usersync.conf:/etc/logstash/conf.d/usersync.conf
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

#  airflow-init:
#    <<: *airflow-common
#    container_name: airflow_init
#    entrypoint: /bin/bash
#    command:
#      - -c
#      - pip install airflow-provider-kafka &&  airflow users list || ( airflow db init &&
#        airflow users create
#        --role Admin
#        --username airflow
#        --password airflow
#        --email airflow@airflow.com
#        --firstname airflow
#        --lastname airflow ) && tail -f /dev/null
#    restart: on-failure
#  airflow-webserver:
#    <<: *airflow-common
#    command: airflow webserver
#    ports:
#      - "8090:8080"
#    container_name: airflow_webserver
#    restart: always
#
#  airflow-scheduler:
#    <<: *airflow-common
#    command: airflow scheduler
#    container_name: airflow_scheduler
#    restart: always
  redis:
    image: bitnami/redis:latest
    container_name: redis_showtime
    environment:
      - REDIS_PASSWORD=123456
      - REDIS_DISABLE_COMMANDS=FLUSHDB,FLUSHALL,CONFIG
      - REDIS_AOF_ENABLED=no
      - REDIS_PORT_NUMBER=6379
      - REDIS_IO_THREADS=4
      - REDIS_IO_THREADS_DO_READS=yes
    command: /opt/bitnami/scripts/redis/run.sh --maxmemory 100mb --maxmemory-policy allkeys-lru
    ports:
      - '6379:6379'
    volumes:
      - ./__w/showtime_API/showtime_API/redis/data:/bitnami/redis/data
volumes:
  local_pgdata:
  pgadmin-data:
  elasticsearch-data:
    driver: local
networks:
  default:
    name: showtime_network
